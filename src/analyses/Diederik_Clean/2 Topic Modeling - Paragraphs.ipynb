{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a997d4",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightgreen; border-radius: 5px; padding: 10px;\">\n",
    "    <h4>Topic Modeling</h4>\n",
    "    <p>...</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ce873f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from preprocessing_functions import *\n",
    "from topic_modeling_functions import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Saving and visualising lda models\n",
    "import gensim\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b659e3b",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "de310c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dir = '../../../../data_clean/paragraphs_lemmatised/'\n",
    "POS = [\"NOUN\", \"VERB\", \"ADJ\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ONLY_ENGLISH_WORDS = True\n",
    "merged_POS = True\n",
    "saving = True\n",
    "\n",
    "# Don't change!\n",
    "word_type = 'english_words' if ONLY_ENGLISH_WORDS else 'dirty_words'\n",
    "files_output_dir = f\"{files_dir}/{word_type}_merged_{''.join(POS)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dfea9f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{files_dir}/merged_{''.join(POS)}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5f5d1",
   "metadata": {},
   "source": [
    "### Merge POS (Should be removed to pre-processing notebook!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e89daac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../data_clean/paragraphs_lemmatised//english_words_merged_NOUNVERBADJ\\paragraphs_10_934384_1038204_merged_POS.csv already exists.\n",
      "../../../../data_clean/paragraphs_lemmatised//english_words_merged_NOUNVERBADJ\\paragraphs_11_1038204_1142024_merged_POS.csv already exists.\n",
      "../../../../data_clean/paragraphs_lemmatised//english_words_merged_NOUNVERBADJ\\paragraphs_12_1142024_1245844_merged_POS.csv already exists.\n"
     ]
    }
   ],
   "source": [
    "# for file in os.listdir()\n",
    "for file in os.listdir(files_dir)[:]:\n",
    "    if file.endswith(\".csv\"):\n",
    "        \n",
    "        output_fp = os.path.join(files_output_dir, file.replace('preprocessed', 'merged_POS'))\n",
    "        \n",
    "        if os.path.isfile(output_fp):\n",
    "            print(f\"{output_fp} already exists.\")\n",
    "            continue\n",
    "            \n",
    "        fp = os.path.join(files_dir, file)\n",
    "        temp_df = pd.read_csv(fp)\n",
    "\n",
    "        if merged_POS:\n",
    "            os.makedirs(files_output_dir, exist_ok=True)\n",
    "            temp_df['merged_POS'] = [[] for _ in range(temp_df.shape[0])]\n",
    "\n",
    "        for tag in POS:\n",
    "            if ONLY_ENGLISH_WORDS:\n",
    "                        column_name = f'{tag}_clean'   \n",
    "            else:\n",
    "                column_name = f'{tag}'\n",
    "\n",
    "            string_to_list = temp_df[column_name].apply(literal_eval)\n",
    "\n",
    "            if merged_POS:\n",
    "                temp_df['merged_POS'] += string_to_list\n",
    "        \n",
    "        # Save df\n",
    "        temp_df = temp_df[['city_1', 'city_2', 'paragraph_id', 'paragraph', 'article_id', 'title', 'merged_POS']]\n",
    "        temp_df.to_csv(output_fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8bf283ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_1</th>\n",
       "      <th>city_2</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>merged_POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paris</td>\n",
       "      <td>London</td>\n",
       "      <td>830565</td>\n",
       "      <td>Piip was a member of the Estonian Province Ass...</td>\n",
       "      <td>11414959</td>\n",
       "      <td>Ants Piip</td>\n",
       "      <td>[member, member, member, delegation, peace, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>London</td>\n",
       "      <td>Paris</td>\n",
       "      <td>830566</td>\n",
       "      <td>Piip was a member of the Estonian Province Ass...</td>\n",
       "      <td>11414959</td>\n",
       "      <td>Ants Piip</td>\n",
       "      <td>[member, member, member, delegation, peace, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paris</td>\n",
       "      <td>Munich</td>\n",
       "      <td>830567</td>\n",
       "      <td>Humphrey was born in Saint John, New Brunswick...</td>\n",
       "      <td>11415024</td>\n",
       "      <td>Jack Humphrey</td>\n",
       "      <td>[school, student, school, bear, study, travel,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Munich</td>\n",
       "      <td>Paris</td>\n",
       "      <td>830568</td>\n",
       "      <td>Humphrey was born in Saint John, New Brunswick...</td>\n",
       "      <td>11415024</td>\n",
       "      <td>Jack Humphrey</td>\n",
       "      <td>[school, student, school, bear, study, travel,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turin</td>\n",
       "      <td>Bologna</td>\n",
       "      <td>830569</td>\n",
       "      <td>Born in Bologna, at the age of 15, he began tr...</td>\n",
       "      <td>11415085</td>\n",
       "      <td>Giuseppe Pedretti</td>\n",
       "      <td>[age, opposition, family, son, studio, bear, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_1   city_2  paragraph_id  \\\n",
       "0   Paris   London        830565   \n",
       "1  London    Paris        830566   \n",
       "2   Paris   Munich        830567   \n",
       "3  Munich    Paris        830568   \n",
       "4   Turin  Bologna        830569   \n",
       "\n",
       "                                           paragraph  article_id  \\\n",
       "0  Piip was a member of the Estonian Province Ass...    11414959   \n",
       "1  Piip was a member of the Estonian Province Ass...    11414959   \n",
       "2  Humphrey was born in Saint John, New Brunswick...    11415024   \n",
       "3  Humphrey was born in Saint John, New Brunswick...    11415024   \n",
       "4  Born in Bologna, at the age of 15, he began tr...    11415085   \n",
       "\n",
       "               title                                         merged_POS  \n",
       "0          Ants Piip  [member, member, member, delegation, peace, ne...  \n",
       "1          Ants Piip  [member, member, member, delegation, peace, ne...  \n",
       "2      Jack Humphrey  [school, student, school, bear, study, travel,...  \n",
       "3      Jack Humphrey  [school, student, school, bear, study, travel,...  \n",
       "4  Giuseppe Pedretti  [age, opposition, family, son, studio, bear, b...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[['city_1', 'city_2', 'paragraph_id', 'paragraph', 'article_id', 'title', 'merged_POS']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "150f13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "\n",
    "for file in tqdm(os.listdir(files_output_dir)):\n",
    "    fp = os.path.join(files_output_dir, file)\n",
    "    \n",
    "    temp_df = pd.read_csv(fp)\n",
    "    dataframes.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3313f5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "538ef30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_1</th>\n",
       "      <th>city_2</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>merged_POS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paragraph_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Florence</td>\n",
       "      <td>The first community of adherents of the Baha'i...</td>\n",
       "      <td>303</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>['community', 'adherent', 'center', 'found', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florence</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>The first community of adherents of the Baha'i...</td>\n",
       "      <td>303</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>['community', 'adherent', 'center', 'found', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paris</td>\n",
       "      <td>London</td>\n",
       "      <td>A major revision of the work by composer and a...</td>\n",
       "      <td>309</td>\n",
       "      <td>An American in Paris</td>\n",
       "      <td>['revision', 'work', 'composer', 'arranger', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London</td>\n",
       "      <td>Paris</td>\n",
       "      <td>A major revision of the work by composer and a...</td>\n",
       "      <td>309</td>\n",
       "      <td>An American in Paris</td>\n",
       "      <td>['revision', 'work', 'composer', 'arranger', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Madrid</td>\n",
       "      <td>Rome</td>\n",
       "      <td>Access to biocapacity in Algeria is lower than...</td>\n",
       "      <td>358</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>['access', 'world', 'hectare', 'person', 'terr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076400</th>\n",
       "      <td>Paris</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Mundhir participated in Arab and international...</td>\n",
       "      <td>70585176</td>\n",
       "      <td>Mundhir Masri</td>\n",
       "      <td>['festival', 'seminar', 'guest', 'participate'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076401</th>\n",
       "      <td>London</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Mundhir participated in Arab and international...</td>\n",
       "      <td>70585176</td>\n",
       "      <td>Mundhir Masri</td>\n",
       "      <td>['festival', 'seminar', 'guest', 'participate'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076402</th>\n",
       "      <td>London</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Mundhir participated in Arab and international...</td>\n",
       "      <td>70585176</td>\n",
       "      <td>Mundhir Masri</td>\n",
       "      <td>['festival', 'seminar', 'guest', 'participate'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076403</th>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Mundhir participated in Arab and international...</td>\n",
       "      <td>70585176</td>\n",
       "      <td>Mundhir Masri</td>\n",
       "      <td>['festival', 'seminar', 'guest', 'participate'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076404</th>\n",
       "      <td>Stockholm</td>\n",
       "      <td>London</td>\n",
       "      <td>Mundhir participated in Arab and international...</td>\n",
       "      <td>70585176</td>\n",
       "      <td>Mundhir Masri</td>\n",
       "      <td>['festival', 'seminar', 'guest', 'participate'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2076404 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  city_1      city_2  \\\n",
       "paragraph_id                           \n",
       "1             Birmingham    Florence   \n",
       "2               Florence  Birmingham   \n",
       "3                  Paris      London   \n",
       "4                 London       Paris   \n",
       "5                 Madrid        Rome   \n",
       "...                  ...         ...   \n",
       "2076400            Paris   Stockholm   \n",
       "2076401           London       Paris   \n",
       "2076402           London   Stockholm   \n",
       "2076403        Stockholm       Paris   \n",
       "2076404        Stockholm      London   \n",
       "\n",
       "                                                      paragraph  article_id  \\\n",
       "paragraph_id                                                                  \n",
       "1             The first community of adherents of the Baha'i...         303   \n",
       "2             The first community of adherents of the Baha'i...         303   \n",
       "3             A major revision of the work by composer and a...         309   \n",
       "4             A major revision of the work by composer and a...         309   \n",
       "5             Access to biocapacity in Algeria is lower than...         358   \n",
       "...                                                         ...         ...   \n",
       "2076400       Mundhir participated in Arab and international...    70585176   \n",
       "2076401       Mundhir participated in Arab and international...    70585176   \n",
       "2076402       Mundhir participated in Arab and international...    70585176   \n",
       "2076403       Mundhir participated in Arab and international...    70585176   \n",
       "2076404       Mundhir participated in Arab and international...    70585176   \n",
       "\n",
       "                             title  \\\n",
       "paragraph_id                         \n",
       "1                          Alabama   \n",
       "2                          Alabama   \n",
       "3             An American in Paris   \n",
       "4             An American in Paris   \n",
       "5                          Algeria   \n",
       "...                            ...   \n",
       "2076400              Mundhir Masri   \n",
       "2076401              Mundhir Masri   \n",
       "2076402              Mundhir Masri   \n",
       "2076403              Mundhir Masri   \n",
       "2076404              Mundhir Masri   \n",
       "\n",
       "                                                     merged_POS  \n",
       "paragraph_id                                                     \n",
       "1             ['community', 'adherent', 'center', 'found', '...  \n",
       "2             ['community', 'adherent', 'center', 'found', '...  \n",
       "3             ['revision', 'work', 'composer', 'arranger', '...  \n",
       "4             ['revision', 'work', 'composer', 'arranger', '...  \n",
       "5             ['access', 'world', 'hectare', 'person', 'terr...  \n",
       "...                                                         ...  \n",
       "2076400       ['festival', 'seminar', 'guest', 'participate'...  \n",
       "2076401       ['festival', 'seminar', 'guest', 'participate'...  \n",
       "2076402       ['festival', 'seminar', 'guest', 'participate'...  \n",
       "2076403       ['festival', 'seminar', 'guest', 'participate'...  \n",
       "2076404       ['festival', 'seminar', 'guest', 'participate'...  \n",
       "\n",
       "[2076404 rows x 6 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frames = [citypair['lemmatized_paragraphs'] for citypair in data_list]\n",
    "# citypairs = [citypair['city_pair'] for citypair in data_list]\n",
    "\n",
    "result = pd.concat(dataframes) #, keys=citypairs)\n",
    "result.set_index('paragraph_id', inplace=True)\n",
    "result.sort_index(inplace=True)\n",
    "# result.reset_index(inplace=True)\n",
    "\n",
    "# paris_london = result.loc[\"paris_london\"]\n",
    "# paris_london.set_index('paragraph_id', inplace=True)\n",
    "# paris_london\n",
    "\n",
    "result #.iloc[21051]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a8fecd",
   "metadata": {},
   "source": [
    "## Vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1e1536fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10min 52s\n",
      "Wall time: 13min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result.merged_POS =  result.merged_POS.apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ac73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "paragraphs = result.merged_POS\n",
    "MIN_DF = 0.1\n",
    "MAX_DF = 0.8\n",
    "\n",
    "# Vectorization\n",
    "dictionary, corpus = vectorize(paragraphs, MIN_DF=MIN_DF, MAX_DF=MAX_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3911d99",
   "metadata": {},
   "source": [
    "## Train Single LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33be613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOPICS = # e.g. 6\n",
    "model_dict = train_lda_model(lemmatized_text=paragraphs,\n",
    "                            dictionary=dictionary,\n",
    "                            corpus=corpus,\n",
    "                            MIN_DF=MIN_DF,\n",
    "                            MAX_DF=MAX_DF,\n",
    "                            N_TOPICS=N_TOPICS\n",
    "                            # random_seed=0, should be added to allow the same results!\n",
    "                            )\n",
    "\n",
    "print(model_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dcf246",
   "metadata": {},
   "source": [
    "## Load Single LDA Model\n",
    "\n",
    "### Only run if a). you want to load a previously trained model or b). the model_dict variable is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fdf9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give path to model\n",
    "single_model_path = #\n",
    "forced_single_model_path = os.path.abspath(single_model_path)\n",
    "\n",
    "# model = load_lda_model(forced_single_model_path, LOAD_VIS=True, LOAD_DICT=True, LOAD_TEXTS=True, LOAD_COHERENCE_SCORE=True)\n",
    "\n",
    "LOAD_VIS=True,\n",
    "LOAD_DICT=True,\n",
    "LOAD_TEXTS=True,\n",
    "LOAD_COHERENCE_SCORE=True\n",
    "\n",
    "if os.path.exists(forced_single_model_path):\n",
    "    model_dict = load_lda_model(forced_single_model_path,\n",
    "                           LOAD_VIS=LOAD_VIS,\n",
    "                           LOAD_DICT=LOAD_DICT,\n",
    "                           LOAD_TEXTS=LOAD_TEXTS,\n",
    "                           LOAD_COHERENCE_SCORE=LOAD_COHERENCE_SCORE)\n",
    "    print(model_dict.keys())\n",
    "else:\n",
    "    print('Path is invalid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b7a18",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e66a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_topics(lda_model, corpus, dictionary, sort_topics=False):\n",
    "    lda_conv = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(lda_model)\n",
    "    vis = gensimvis.prepare(lda_conv, corpus, dictionary, sort_topics=False)\n",
    "    \n",
    "    print(vis.topic_order)\n",
    "    \n",
    "    return vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c90f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "if 'visualisation' not in model_dict.keys():\n",
    "    vis = visualise_topics(model_dict['lda_model'], corpus, dictionary)\n",
    "else:\n",
    "    vis = model_dict['visualisation']\n",
    "\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de47ea33",
   "metadata": {},
   "source": [
    "## Get most relevant words per topic\n",
    "\n",
    "#### (used to create the topic vectors in the word embedding classification method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8f8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = {}\n",
    "num_terms = 15 # Adjust number of words to represent each topic\n",
    "lambd = 0.2 # Adjust this accordingly based on tuning above\n",
    "\n",
    "if not isinstance(vis, pyLDAvis._prepare.PreparedData):\n",
    "    vis = visualise_topics(model_dict['lda_model'], corpus, dictionary)\n",
    "    \n",
    "for i in range(1,len(model_dict['lda_model'].get_topics())+1): #Adjust this to reflect number of topics chosen for final LDA model\n",
    "    topic = vis.topic_info[vis.topic_info.Category == 'Topic'+str(i)].copy()\n",
    "    topic['relevance'] = topic['loglift']*(1-lambd)+topic['logprob']*lambd\n",
    "    all_topics['Topic '+str(i)] = topic.sort_values(by='relevance', ascending=False).Term[:num_terms].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03ab592",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_topics).T\n",
    "# display(all_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6738d6a",
   "metadata": {},
   "source": [
    "## Word Topic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5edc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOPICS = len(model_dict['lda_model'].get_topics())\n",
    "MAX_WORDS = 8\n",
    "\n",
    "for i in range(N_TOPICS):\n",
    "    topic_words = model_dict['lda_model'].show_topic(i, topn=MAX_WORDS)\n",
    "    print(i+1, [(x[0], round(x[1], 3)) for x in topic_words])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e2fb16",
   "metadata": {},
   "source": [
    "## Document (=paragraphs) topic distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005956dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_docs = model_dict['lda_model'].load_document_topics()\n",
    "topic_distributions = pd.DataFrame([[x[1] for x in doc] for doc in transformed_docs], \n",
    "             columns=['topic_{}'.format(i+1) for i in range(N_TOPICS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea76031",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distributions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f13232",
   "metadata": {},
   "source": [
    "## Rename Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733bb06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give Topics sensible names\n",
    "# topic_distributions_renamed_cols=topic_distributions.rename(columns = { 'topic_1': 'lda_sport',\n",
    "#                                         'topic_2': 'lda_art',\n",
    "#                                         'topic_3': 'lda_diplomacy',\n",
    "#                                         'topic_4': 'lda_entertainment',\n",
    "#                                         'topic_5': 'lda_transportation',\n",
    "#                                         'topic_6': 'lda_education'}, inplace = False)\n",
    "\n",
    "topic_distributions_renamed_cols.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9070ac48",
   "metadata": {},
   "source": [
    "## Topic Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69202620",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distributions_renamed_cols.idxmax(axis=\"columns\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60410dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distributions_renamed_cols.idxmax(axis=\"columns\").value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e7f2f5",
   "metadata": {},
   "source": [
    "## Merge paragraphs with topic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a58a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_results = pd.concat([result, topic_distributions_renamed_cols],\n",
    "                  axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f84d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_results.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035638f5",
   "metadata": {},
   "source": [
    "## Get dominant topic and score of chunked dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_chunks = (len(updated_results) // 10000) + 1\n",
    "\n",
    "chunked_dataframe = np.array_split(updated_results, nr_of_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0caca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take a while\n",
    "\n",
    "for i, subdataframe in enumerate(tqdm(chunked_dataframe)):\n",
    "    chunked_dataframe[i] = pd.concat([subdataframe, subdataframe[topic_distributions_renamed_cols.columns].agg(['idxmax','max'],axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ee856",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(chunked_dataframe,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b0c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_renamed_cols = final_df.rename(columns = { 'idxmax': 'lda_dominant',\n",
    "                                        'max': 'lda_dominant_score'}, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9db48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_renamed_cols.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d64e00",
   "metadata": {},
   "source": [
    "## Query of 3 city pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a72ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires work due to city pair in two columns\n",
    "# three_city_pairs = final_df_renamed_cols[final_df_renamed_cols['city_pair'].isin(['paris_milan', 'barcelona_manchester', 'warsaw_prague'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2608ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(three_city_pairs.groupby('city_pair')['lda_dominant'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957eb87a",
   "metadata": {},
   "source": [
    "## Save document topic distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b5c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "num, div = len(all_paragraphs_df), 20\n",
    "chunks = [num // div + (1 if x < num % div else 0)  for x in range (div)]\n",
    "cum_chunks = [0]\n",
    "\n",
    "for i, x in enumerate(chunks):\n",
    "    cum_chunks.append(sum(chunks[:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46df7703",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_min_max = list(zip(cum_chunks, cum_chunks[1:]))\n",
    "chunks_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba7ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"../../../../data_clean/paragraphs_lda_topic_distribution\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "count = 1\n",
    "for chunk in tqdm(chunks_min_max):\n",
    "    sub_df = all_paragraphs_df.iloc[chunk[0]:chunk[1]]\n",
    "    file_path = f\"{output_folder}/paragraphs_{count}_{chunk[0]}_{chunk[1]}_lda_topics.csv\"\n",
    "    sub_df.to_csv(file_path, index=False)\n",
    "    count += 1\n",
    "    \n",
    "# final_df_renamed_cols.to_csv('..\\..\\..\\..\\..\\data\\clean\\lda_classified_30cities_435citypairs_311k_paragraphs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680b59ea",
   "metadata": {},
   "source": [
    "## Distribution of dominant topic scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48925805",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_renamed_cols['lda_dominant_score'].value_counts(bins=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b16518",
   "metadata": {},
   "source": [
    "## Graphed density of the grouped topic scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53195cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "a = final_df_renamed_cols.groupby('lda_dominant')\n",
    "\n",
    "# Iterate through the five airlines\n",
    "for topic in final_df_renamed_cols['lda_dominant'].unique():\n",
    "    b = a['lda_dominant_score'].get_group(topic)\n",
    "    \n",
    "    #     b.plot.density(color='green')\n",
    "    # plt.title('Density plot for Speeding')\n",
    "    # plt.show()\n",
    "    \n",
    "    sns.distplot(b, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 2},\n",
    "                 label = topic)\n",
    "    \n",
    "# Plot formatting\n",
    "sns.distplot(final_df_renamed_cols['lda_dominant_score'], hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 4},\n",
    "                 color = 'black',\n",
    "                 label = 'Average')\n",
    "\n",
    "plt.legend(prop={'size': 20}, title = 'Topic', title_fontsize=22)\n",
    "# plt.title('Score Density of the dominant topics grouped by topic', fontsize=24)\n",
    "plt.rc('axes', titlesize=24)\n",
    "plt.rc('axes', labelsize=24)\n",
    "plt.rc('xtick', labelsize=24)\n",
    "plt.rc('ytick', labelsize=24)\n",
    "plt.xlabel('Topic Dominance')\n",
    "plt.ylim(0, 12)\n",
    "plt.xlim(0.2, 1)\n",
    "plt.ylabel('Density')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41f4a23",
   "metadata": {},
   "source": [
    "# EXTRAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b21b1",
   "metadata": {},
   "source": [
    "## Training Multiple LDA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf138ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_SELECTION = range(2,21, 1)\n",
    "list(TOPIC_SELECTION)\n",
    "\n",
    "\n",
    "%%time\n",
    "\n",
    "paragraphs = result.merged_POS\n",
    "# MIN_DF = 0.1\n",
    "# MAX_DF = 0.8\n",
    "\n",
    "# Vectorization\n",
    "# dictionary, corpus = vectorize(paragraphs, MIN_DF=MIN_DF, MAX_DF=MAX_DF)\n",
    "\n",
    "models = compare_lda_models(OUTPUT_DIR='../../../../../data/clean/lda_models/50k_paragraphs/', TOPIC_SELECTION=TOPIC_SELECTION,\n",
    "                LEMMATIZED_TEXT=paragraphs, DICTIONARY=dictionary, CORPUS=corpus, MIN_DF=MIN_DF, MAX_DF=MAX_DF, N_ITERATIONS=1000,\n",
    "                PATH_TO_MALLET=r'C:/mallet/bin/mallet.bat', GET_COHERENCE_SCORE=True, COHERENCE='c_v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb7bfe0",
   "metadata": {},
   "source": [
    "## Load Multiple LDA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b3b69f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
