{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab4bc67",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightgreen; border-radius: 5px; padding: 10px;\">\n",
    "    <h4>Pre-processing Paragraphs</h4>\n",
    "    <p>...</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8aa869",
   "metadata": {},
   "source": [
    "## Packages and Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96a5d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Packages\n",
    "import os\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Import Scripts\n",
    "from preprocessing_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6e9900",
   "metadata": {},
   "source": [
    "## Pre-processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4be34908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatise_city_pair(df, POS, OVERWRITE=False, ONLY_ENGLISH_WORDS=False, ENGLISH_WORDS = [],\n",
    "    english_words_file=\"../../../input/english_words_alpha_370k.txt\", NLP_MAX_LENGTH=1500000):\n",
    "    \n",
    "    for tag in tqdm(POS, desc=f\"POS: {POS}\", leave=False):\n",
    "        if OVERWRITE or tag not in df.columns:\n",
    "            df.loc[:, f\"{tag}\"] = lemmatise_paragraphs(paragraphs=df.loc[:, 'paragraph'], POStag=tag, NLP_MAX_LENGTH=NLP_MAX_LENGTH)\n",
    "\n",
    "        if ONLY_ENGLISH_WORDS and (OVERWRITE or f'{tag}_clean' not in df.columns):\n",
    "            df.loc[:, f'{tag}_clean'] = keep_english_words_in_paragraphs(paragraphs=df.loc[:, tag], english_words=ENGLISH_WORDS)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab9588b",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0829e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../../../data_clean/' # directory where selected articles will be saved, change if you want to save these elsewhere\n",
    "out_dir = 'output/'\n",
    "in_dir = '../../input/'\n",
    "# extr_dir = path/to/wikidump/ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32408cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS = [\"NOUN\", \"VERB\", \"ADJ\"]\n",
    "OVERWRITE=False\n",
    "ONLY_ENGLISH_WORDS=True\n",
    "NLP_MAX_LENGTH = 1500000\n",
    "\n",
    "ENGLISH_WORDS = get_english_words(path=f\"{in_dir}english_words_alpha_370k.txt\")\n",
    "# df =  pd.read_csv(\"../../../../../data/clean/paragraphs/paragraphs_raw_folder_62.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d359e37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd0b8f062fc431d879df24994a8b102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pre-processing paragraphs...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_paragraphs_df = pd.DataFrame(columns= ['city_1', 'city_2', 'paragraph_id', 'paragraph', 'article_id', 'title'])\n",
    "\n",
    "for file in tqdm(os.listdir(paragraphs_dir), desc= 'Pre-processing paragraphs...'):\n",
    "    fp = os.path.join(paragraphs_dir, file)\n",
    "    filename = file.split('.')[0]\n",
    "    \n",
    "    df = pd.read_csv(fp)\n",
    "    all_paragraphs_df = pd.concat([all_paragraphs_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4f1f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "num, div = len(all_paragraphs_df), 20\n",
    "chunks = [num // div + (1 if x < num % div else 0)  for x in range (div)]\n",
    "cum_chunks = [0]\n",
    "\n",
    "for i, x in enumerate(chunks):\n",
    "    cum_chunks.append(sum(chunks[:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc92239e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 103821),\n",
       " (103821, 207642),\n",
       " (207642, 311463),\n",
       " (311463, 415284),\n",
       " (415284, 519104),\n",
       " (519104, 622924),\n",
       " (622924, 726744),\n",
       " (726744, 830564),\n",
       " (830564, 934384),\n",
       " (934384, 1038204),\n",
       " (1038204, 1142024),\n",
       " (1142024, 1245844),\n",
       " (1245844, 1349664),\n",
       " (1349664, 1453484),\n",
       " (1453484, 1557304),\n",
       " (1557304, 1661124),\n",
       " (1661124, 1764944),\n",
       " (1764944, 1868764),\n",
       " (1868764, 1972584),\n",
       " (1972584, 2076404)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_min_max = list(zip(cum_chunks, cum_chunks[1:]))\n",
    "chunks_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7efaac71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef40ce6f7dbb4bf9a10be4343cac82f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = 1\n",
    "for chunk in tqdm(chunks_min_max):\n",
    "    sub_df = all_paragraphs_df.iloc[chunk[0]:chunk[1]]\n",
    "    file_path = f\"paragraphs_{count}_{chunk[0]}_{chunk[1]}.csv\"\n",
    "    sub_df.to_csv(file_path, index=False)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae02098",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20a40ca8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d9b14679c5458c9226ba2cf4d24dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pre-processing paragraphs...:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "POS: ['NOUN', 'VERB', 'ADJ']:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (NOUN)...:   0%|          | 0/103821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (VERB)...:   0%|          | 0/103821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (ADJ)...:   0%|          | 0/103821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed paragraphs_1_0_103821, containing 103821 paragraphs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "POS: ['NOUN', 'VERB', 'ADJ']:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (NOUN)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (VERB)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (ADJ)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed paragraphs_20_1972584_2076404, containing 103820 paragraphs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "POS: ['NOUN', 'VERB', 'ADJ']:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (NOUN)...:   0%|          | 0/103821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (VERB)...:   0%|          | 0/103821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (ADJ)...:   0%|          | 0/103821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed paragraphs_2_103821_207642, containing 103821 paragraphs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "POS: ['NOUN', 'VERB', 'ADJ']:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (NOUN)...:   0%|          | 0/103821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (VERB)...:   0%|          | 0/103821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (ADJ)...:   0%|          | 0/103821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed paragraphs_3_207642_311463, containing 103821 paragraphs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "POS: ['NOUN', 'VERB', 'ADJ']:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (NOUN)...:   0%|          | 0/103821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (VERB)...:   0%|          | 0/103821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (ADJ)...:   0%|          | 0/103821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed paragraphs_4_311463_415284, containing 103821 paragraphs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "POS: ['NOUN', 'VERB', 'ADJ']:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (NOUN)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (VERB)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (ADJ)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed paragraphs_5_415284_519104, containing 103820 paragraphs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "POS: ['NOUN', 'VERB', 'ADJ']:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (NOUN)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (VERB)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (ADJ)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed paragraphs_6_519104_622924, containing 103820 paragraphs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "POS: ['NOUN', 'VERB', 'ADJ']:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (NOUN)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (VERB)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (ADJ)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed paragraphs_7_622924_726744, containing 103820 paragraphs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "POS: ['NOUN', 'VERB', 'ADJ']:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (NOUN)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (VERB)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (ADJ)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed paragraphs_8_726744_830564, containing 103820 paragraphs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "POS: ['NOUN', 'VERB', 'ADJ']:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (NOUN)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (VERB)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (ADJ)...:   0%|          | 0/103820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed paragraphs_9_830564_934384, containing 103820 paragraphs.\n"
     ]
    }
   ],
   "source": [
    "paragraphs_dir = os.path.join(data_dir, 'paragraphs_smaller')\n",
    "\n",
    "\n",
    "for file in tqdm(os.listdir(paragraphs_dir), desc= 'Pre-processing paragraphs...'):\n",
    "    fp = os.path.join(paragraphs_dir, file)\n",
    "    filename = file.split('.')[0]\n",
    "    \n",
    "    if not os.path.exists(f\"{filename}_preprocessed.csv\"):\n",
    "        df = pd.read_csv(fp)\n",
    "\n",
    "        lemmatised_df = lemmatise_city_pair(df=df, POS=POS, OVERWRITE=OVERWRITE, ONLY_ENGLISH_WORDS=ONLY_ENGLISH_WORDS, ENGLISH_WORDS=ENGLISH_WORDS, NLP_MAX_LENGTH=NLP_MAX_LENGTH)\n",
    "        lemmatised_df.to_csv(f\"{filename}_preprocessed.csv\", index=False)\n",
    "\n",
    "        print(f\"Pre-processed {filename}, containing {len(df)} paragraphs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae4f1df",
   "metadata": {},
   "source": [
    "## Everything from here may be deleted later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2e1a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = os.path.join(paragraphs_dir, \"paragraphs_0_101735_test.csv\")\n",
    "df =  pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd1bee4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_1</th>\n",
       "      <th>city_2</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Florence</td>\n",
       "      <td>1</td>\n",
       "      <td>The first community of adherents of the Baha'i...</td>\n",
       "      <td>303</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Florence</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>2</td>\n",
       "      <td>The first community of adherents of the Baha'i...</td>\n",
       "      <td>303</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paris</td>\n",
       "      <td>London</td>\n",
       "      <td>3</td>\n",
       "      <td>A major revision of the work by composer and a...</td>\n",
       "      <td>309</td>\n",
       "      <td>An American in Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London</td>\n",
       "      <td>Paris</td>\n",
       "      <td>4</td>\n",
       "      <td>A major revision of the work by composer and a...</td>\n",
       "      <td>309</td>\n",
       "      <td>An American in Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Madrid</td>\n",
       "      <td>Rome</td>\n",
       "      <td>5</td>\n",
       "      <td>Access to biocapacity in Algeria is lower than...</td>\n",
       "      <td>358</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488331</th>\n",
       "      <td>Dublin</td>\n",
       "      <td>London</td>\n",
       "      <td>488332</td>\n",
       "      <td>Allman-Smith played hockey for Dublin Universi...</td>\n",
       "      <td>3001932</td>\n",
       "      <td>Edward Allman-Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488332</th>\n",
       "      <td>London</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>488333</td>\n",
       "      <td>O'Kelly and Condell met in Dublin in 1969 and ...</td>\n",
       "      <td>3001953</td>\n",
       "      <td>Tir na nOg (band)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488333</th>\n",
       "      <td>Dublin</td>\n",
       "      <td>London</td>\n",
       "      <td>488334</td>\n",
       "      <td>O'Kelly and Condell met in Dublin in 1969 and ...</td>\n",
       "      <td>3001953</td>\n",
       "      <td>Tir na nOg (band)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488334</th>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>488335</td>\n",
       "      <td>Tir na nOg reformed in 1985, releasing the sin...</td>\n",
       "      <td>3001953</td>\n",
       "      <td>Tir na nOg (band)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488335</th>\n",
       "      <td>Dublin</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>488336</td>\n",
       "      <td>Tir na nOg reformed in 1985, releasing the sin...</td>\n",
       "      <td>3001953</td>\n",
       "      <td>Tir na nOg (band)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488336 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            city_1      city_2  paragraph_id  \\\n",
       "0       Birmingham    Florence             1   \n",
       "1         Florence  Birmingham             2   \n",
       "2            Paris      London             3   \n",
       "3           London       Paris             4   \n",
       "4           Madrid        Rome             5   \n",
       "...            ...         ...           ...   \n",
       "488331      Dublin      London        488332   \n",
       "488332      London      Dublin        488333   \n",
       "488333      Dublin      London        488334   \n",
       "488334  Birmingham      Dublin        488335   \n",
       "488335      Dublin  Birmingham        488336   \n",
       "\n",
       "                                                paragraph  article_id  \\\n",
       "0       The first community of adherents of the Baha'i...         303   \n",
       "1       The first community of adherents of the Baha'i...         303   \n",
       "2       A major revision of the work by composer and a...         309   \n",
       "3       A major revision of the work by composer and a...         309   \n",
       "4       Access to biocapacity in Algeria is lower than...         358   \n",
       "...                                                   ...         ...   \n",
       "488331  Allman-Smith played hockey for Dublin Universi...     3001932   \n",
       "488332  O'Kelly and Condell met in Dublin in 1969 and ...     3001953   \n",
       "488333  O'Kelly and Condell met in Dublin in 1969 and ...     3001953   \n",
       "488334  Tir na nOg reformed in 1985, releasing the sin...     3001953   \n",
       "488335  Tir na nOg reformed in 1985, releasing the sin...     3001953   \n",
       "\n",
       "                       title  \n",
       "0                    Alabama  \n",
       "1                    Alabama  \n",
       "2       An American in Paris  \n",
       "3       An American in Paris  \n",
       "4                    Algeria  \n",
       "...                      ...  \n",
       "488331   Edward Allman-Smith  \n",
       "488332     Tir na nOg (band)  \n",
       "488333     Tir na nOg (band)  \n",
       "488334     Tir na nOg (band)  \n",
       "488335     Tir na nOg (band)  \n",
       "\n",
       "[488336 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f70c6637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "POS: ['NOUN', 'VERB', 'ADJ']:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (NOUN)...:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (VERB)...:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lemmatising (ADJ)...:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7min 57s\n",
      "Wall time: 23min 6s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# lemmatised_df = lemmatise_city_pair(df=df[:50000], POS=POS, OVERWRITE=OVERWRITE, ONLY_ENGLISH_WORDS=ONLY_ENGLISH_WORDS, ENGLISH_WORDS=ENGLISH_WORDS, NLP_MAX_LENGTH=NLP_MAX_LENGTH)\n",
    "# lemmatised_df.to_csv(\"lemmatised_file.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "993ebbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_1</th>\n",
       "      <th>city_2</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NOUN_clean</th>\n",
       "      <th>VERB</th>\n",
       "      <th>VERB_clean</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADJ_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Florence</td>\n",
       "      <td>1</td>\n",
       "      <td>The first community of adherents of the Baha'i...</td>\n",
       "      <td>303</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>['community', 'adherent', 'center']</td>\n",
       "      <td>['community', 'adherent', 'center']</td>\n",
       "      <td>['found', 'move', 'exist']</td>\n",
       "      <td>['found', 'move', 'exist']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Florence</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>2</td>\n",
       "      <td>The first community of adherents of the Baha'i...</td>\n",
       "      <td>303</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>['community', 'adherent', 'center']</td>\n",
       "      <td>['community', 'adherent', 'center']</td>\n",
       "      <td>['found', 'move', 'exist']</td>\n",
       "      <td>['found', 'move', 'exist']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paris</td>\n",
       "      <td>London</td>\n",
       "      <td>3</td>\n",
       "      <td>A major revision of the work by composer and a...</td>\n",
       "      <td>309</td>\n",
       "      <td>An American in Paris</td>\n",
       "      <td>['revision', 'work', 'composer', 'arranger', '...</td>\n",
       "      <td>['revision', 'work', 'composer', 'arranger', '...</td>\n",
       "      <td>['simplify', 'reduce', 'eliminate', 'avoid', '...</td>\n",
       "      <td>['simplify', 'reduce', 'eliminate', 'avoid', '...</td>\n",
       "      <td>['major', 'standard', 'original', 'original']</td>\n",
       "      <td>['major', 'standard', 'original', 'original']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London</td>\n",
       "      <td>Paris</td>\n",
       "      <td>4</td>\n",
       "      <td>A major revision of the work by composer and a...</td>\n",
       "      <td>309</td>\n",
       "      <td>An American in Paris</td>\n",
       "      <td>['revision', 'work', 'composer', 'arranger', '...</td>\n",
       "      <td>['revision', 'work', 'composer', 'arranger', '...</td>\n",
       "      <td>['simplify', 'reduce', 'eliminate', 'avoid', '...</td>\n",
       "      <td>['simplify', 'reduce', 'eliminate', 'avoid', '...</td>\n",
       "      <td>['major', 'standard', 'original', 'original']</td>\n",
       "      <td>['major', 'standard', 'original', 'original']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Madrid</td>\n",
       "      <td>Rome</td>\n",
       "      <td>5</td>\n",
       "      <td>Access to biocapacity in Algeria is lower than...</td>\n",
       "      <td>358</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>['access', 'biocapacity', 'world', 'hectare', ...</td>\n",
       "      <td>['access', 'world', 'hectare', 'person', 'terr...</td>\n",
       "      <td>['mean', 'use', 'contain', 'run', 'hold', 'sec...</td>\n",
       "      <td>['mean', 'use', 'contain', 'run', 'hold', 'sec...</td>\n",
       "      <td>['low', 'average', 'global', 'global', 'global...</td>\n",
       "      <td>['low', 'average', 'global', 'global', 'global...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>996</td>\n",
       "      <td>Athens was awarded the 2004 Summer Olympics on...</td>\n",
       "      <td>1216</td>\n",
       "      <td>Athens</td>\n",
       "      <td>['bid', 'time', 'game', 'event', 'bid', 'bid',...</td>\n",
       "      <td>['bid', 'time', 'game', 'event', 'bid', 'bid',...</td>\n",
       "      <td>['award', 'have', 'lose', 'host', 'host', 'fol...</td>\n",
       "      <td>['award', 'have', 'lose', 'host', 'host', 'fol...</td>\n",
       "      <td>['previous', 'second', 'inaugural', 'unsuccess...</td>\n",
       "      <td>['previous', 'second', 'inaugural', 'unsuccess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Rome</td>\n",
       "      <td>Athens</td>\n",
       "      <td>997</td>\n",
       "      <td>Athens was awarded the 2004 Summer Olympics on...</td>\n",
       "      <td>1216</td>\n",
       "      <td>Athens</td>\n",
       "      <td>['bid', 'time', 'game', 'event', 'bid', 'bid',...</td>\n",
       "      <td>['bid', 'time', 'game', 'event', 'bid', 'bid',...</td>\n",
       "      <td>['award', 'have', 'lose', 'host', 'host', 'fol...</td>\n",
       "      <td>['award', 'have', 'lose', 'host', 'host', 'fol...</td>\n",
       "      <td>['previous', 'second', 'inaugural', 'unsuccess...</td>\n",
       "      <td>['previous', 'second', 'inaugural', 'unsuccess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Rome</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>998</td>\n",
       "      <td>Athens was awarded the 2004 Summer Olympics on...</td>\n",
       "      <td>1216</td>\n",
       "      <td>Athens</td>\n",
       "      <td>['bid', 'time', 'game', 'event', 'bid', 'bid',...</td>\n",
       "      <td>['bid', 'time', 'game', 'event', 'bid', 'bid',...</td>\n",
       "      <td>['award', 'have', 'lose', 'host', 'host', 'fol...</td>\n",
       "      <td>['award', 'have', 'lose', 'host', 'host', 'fol...</td>\n",
       "      <td>['previous', 'second', 'inaugural', 'unsuccess...</td>\n",
       "      <td>['previous', 'second', 'inaugural', 'unsuccess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Athens</td>\n",
       "      <td>999</td>\n",
       "      <td>Athens was awarded the 2004 Summer Olympics on...</td>\n",
       "      <td>1216</td>\n",
       "      <td>Athens</td>\n",
       "      <td>['bid', 'time', 'game', 'event', 'bid', 'bid',...</td>\n",
       "      <td>['bid', 'time', 'game', 'event', 'bid', 'bid',...</td>\n",
       "      <td>['award', 'have', 'lose', 'host', 'host', 'fol...</td>\n",
       "      <td>['award', 'have', 'lose', 'host', 'host', 'fol...</td>\n",
       "      <td>['previous', 'second', 'inaugural', 'unsuccess...</td>\n",
       "      <td>['previous', 'second', 'inaugural', 'unsuccess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Rome</td>\n",
       "      <td>1000</td>\n",
       "      <td>Athens was awarded the 2004 Summer Olympics on...</td>\n",
       "      <td>1216</td>\n",
       "      <td>Athens</td>\n",
       "      <td>['bid', 'time', 'game', 'event', 'bid', 'bid',...</td>\n",
       "      <td>['bid', 'time', 'game', 'event', 'bid', 'bid',...</td>\n",
       "      <td>['award', 'have', 'lose', 'host', 'host', 'fol...</td>\n",
       "      <td>['award', 'have', 'lose', 'host', 'host', 'fol...</td>\n",
       "      <td>['previous', 'second', 'inaugural', 'unsuccess...</td>\n",
       "      <td>['previous', 'second', 'inaugural', 'unsuccess...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         city_1      city_2  paragraph_id  \\\n",
       "0    Birmingham    Florence             1   \n",
       "1      Florence  Birmingham             2   \n",
       "2         Paris      London             3   \n",
       "3        London       Paris             4   \n",
       "4        Madrid        Rome             5   \n",
       "..          ...         ...           ...   \n",
       "995      Athens   Stockholm           996   \n",
       "996        Rome      Athens           997   \n",
       "997        Rome   Stockholm           998   \n",
       "998   Stockholm      Athens           999   \n",
       "999   Stockholm        Rome          1000   \n",
       "\n",
       "                                             paragraph  article_id  \\\n",
       "0    The first community of adherents of the Baha'i...         303   \n",
       "1    The first community of adherents of the Baha'i...         303   \n",
       "2    A major revision of the work by composer and a...         309   \n",
       "3    A major revision of the work by composer and a...         309   \n",
       "4    Access to biocapacity in Algeria is lower than...         358   \n",
       "..                                                 ...         ...   \n",
       "995  Athens was awarded the 2004 Summer Olympics on...        1216   \n",
       "996  Athens was awarded the 2004 Summer Olympics on...        1216   \n",
       "997  Athens was awarded the 2004 Summer Olympics on...        1216   \n",
       "998  Athens was awarded the 2004 Summer Olympics on...        1216   \n",
       "999  Athens was awarded the 2004 Summer Olympics on...        1216   \n",
       "\n",
       "                    title                                               NOUN  \\\n",
       "0                 Alabama                ['community', 'adherent', 'center']   \n",
       "1                 Alabama                ['community', 'adherent', 'center']   \n",
       "2    An American in Paris  ['revision', 'work', 'composer', 'arranger', '...   \n",
       "3    An American in Paris  ['revision', 'work', 'composer', 'arranger', '...   \n",
       "4                 Algeria  ['access', 'biocapacity', 'world', 'hectare', ...   \n",
       "..                    ...                                                ...   \n",
       "995                Athens  ['bid', 'time', 'game', 'event', 'bid', 'bid',...   \n",
       "996                Athens  ['bid', 'time', 'game', 'event', 'bid', 'bid',...   \n",
       "997                Athens  ['bid', 'time', 'game', 'event', 'bid', 'bid',...   \n",
       "998                Athens  ['bid', 'time', 'game', 'event', 'bid', 'bid',...   \n",
       "999                Athens  ['bid', 'time', 'game', 'event', 'bid', 'bid',...   \n",
       "\n",
       "                                            NOUN_clean  \\\n",
       "0                  ['community', 'adherent', 'center']   \n",
       "1                  ['community', 'adherent', 'center']   \n",
       "2    ['revision', 'work', 'composer', 'arranger', '...   \n",
       "3    ['revision', 'work', 'composer', 'arranger', '...   \n",
       "4    ['access', 'world', 'hectare', 'person', 'terr...   \n",
       "..                                                 ...   \n",
       "995  ['bid', 'time', 'game', 'event', 'bid', 'bid',...   \n",
       "996  ['bid', 'time', 'game', 'event', 'bid', 'bid',...   \n",
       "997  ['bid', 'time', 'game', 'event', 'bid', 'bid',...   \n",
       "998  ['bid', 'time', 'game', 'event', 'bid', 'bid',...   \n",
       "999  ['bid', 'time', 'game', 'event', 'bid', 'bid',...   \n",
       "\n",
       "                                                  VERB  \\\n",
       "0                           ['found', 'move', 'exist']   \n",
       "1                           ['found', 'move', 'exist']   \n",
       "2    ['simplify', 'reduce', 'eliminate', 'avoid', '...   \n",
       "3    ['simplify', 'reduce', 'eliminate', 'avoid', '...   \n",
       "4    ['mean', 'use', 'contain', 'run', 'hold', 'sec...   \n",
       "..                                                 ...   \n",
       "995  ['award', 'have', 'lose', 'host', 'host', 'fol...   \n",
       "996  ['award', 'have', 'lose', 'host', 'host', 'fol...   \n",
       "997  ['award', 'have', 'lose', 'host', 'host', 'fol...   \n",
       "998  ['award', 'have', 'lose', 'host', 'host', 'fol...   \n",
       "999  ['award', 'have', 'lose', 'host', 'host', 'fol...   \n",
       "\n",
       "                                            VERB_clean  \\\n",
       "0                           ['found', 'move', 'exist']   \n",
       "1                           ['found', 'move', 'exist']   \n",
       "2    ['simplify', 'reduce', 'eliminate', 'avoid', '...   \n",
       "3    ['simplify', 'reduce', 'eliminate', 'avoid', '...   \n",
       "4    ['mean', 'use', 'contain', 'run', 'hold', 'sec...   \n",
       "..                                                 ...   \n",
       "995  ['award', 'have', 'lose', 'host', 'host', 'fol...   \n",
       "996  ['award', 'have', 'lose', 'host', 'host', 'fol...   \n",
       "997  ['award', 'have', 'lose', 'host', 'host', 'fol...   \n",
       "998  ['award', 'have', 'lose', 'host', 'host', 'fol...   \n",
       "999  ['award', 'have', 'lose', 'host', 'host', 'fol...   \n",
       "\n",
       "                                                   ADJ  \\\n",
       "0                                                   []   \n",
       "1                                                   []   \n",
       "2        ['major', 'standard', 'original', 'original']   \n",
       "3        ['major', 'standard', 'original', 'original']   \n",
       "4    ['low', 'average', 'global', 'global', 'global...   \n",
       "..                                                 ...   \n",
       "995  ['previous', 'second', 'inaugural', 'unsuccess...   \n",
       "996  ['previous', 'second', 'inaugural', 'unsuccess...   \n",
       "997  ['previous', 'second', 'inaugural', 'unsuccess...   \n",
       "998  ['previous', 'second', 'inaugural', 'unsuccess...   \n",
       "999  ['previous', 'second', 'inaugural', 'unsuccess...   \n",
       "\n",
       "                                             ADJ_clean  \n",
       "0                                                   []  \n",
       "1                                                   []  \n",
       "2        ['major', 'standard', 'original', 'original']  \n",
       "3        ['major', 'standard', 'original', 'original']  \n",
       "4    ['low', 'average', 'global', 'global', 'global...  \n",
       "..                                                 ...  \n",
       "995  ['previous', 'second', 'inaugural', 'unsuccess...  \n",
       "996  ['previous', 'second', 'inaugural', 'unsuccess...  \n",
       "997  ['previous', 'second', 'inaugural', 'unsuccess...  \n",
       "998  ['previous', 'second', 'inaugural', 'unsuccess...  \n",
       "999  ['previous', 'second', 'inaugural', 'unsuccess...  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_df = pd.read_csv('lemmatised_file.csv')\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8c634d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
